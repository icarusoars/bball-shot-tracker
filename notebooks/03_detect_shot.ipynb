{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Whether a Shot Has Happened\n",
    "\n",
    "I found out that it is very costly to run detectron keypoint detector and instance predictor on every single frame of a video.\n",
    "Even with GPU acceleration, processing one second of a video takes around (24 frames) x 1 second = 24 seconds\n",
    "\n",
    "Thus, it is important to identify the parts of the video where a shot is happening first using a non-DeepLearning method.\n",
    "\n",
    "This notebook uses non-compute intensive image-processing techniques to locate the basketball and determine when a shot is happening.\n",
    "\n",
    "Inspired by: https://www.youtube.com/watch?v=QKVpIo5sfGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "import skvideo.datasets\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a Function on an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../data/shooting_vids/blah.png\")\n",
    "output = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# output = locate_bball(gray, output)\n",
    "# output = get_connected_components(gray, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"test result\", np.hstack([output]))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Processing Functions\n",
    "\n",
    "(some functions are unused in the pipeline. Just there because I experimented different image processing methodologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moving_foreground(prev_frame, frame, next_frame):\n",
    "    \"\"\"\n",
    "        Use Three Frame Difference Approach to get moving Foreground Object\n",
    "        in one frame\n",
    "        Reference this blog post:\n",
    "            https://sam-low.com/opencv/frame-differencing.html\n",
    "    \"\"\"\n",
    "    # get differences between frames to detect motion\n",
    "    diff1 = cv2.absdiff(prev_frame, frame)\n",
    "    diff2 = cv2.absdiff(frame, next_frame)\n",
    "    \n",
    "    # increase contrast between foreground and background by thresholding\n",
    "    threshold_value = 10\n",
    "    set_to_value = 255\n",
    "    _, diff1 = cv2.threshold(diff1, threshold_value, set_to_value, cv2.THRESH_BINARY)\n",
    "    _, diff2 = cv2.threshold(diff2, threshold_value, set_to_value, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # find the overlap between the difference frames to get moving object\n",
    "    overlap = cv2.bitwise_and(diff1, diff2)\n",
    "    \n",
    "    # use median filtering to fill some holes of the moving foreground\n",
    "    overlap = cv2.medianBlur(overlap,5)\n",
    "    \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_subtraction(bg_frame, cur_frame):\n",
    "    \n",
    "    \"\"\"\n",
    "        This process of subtracting current frame from bg reference frame\n",
    "        DOES NOT work well.\n",
    "        This is because if the camera tilts or shifts slightly the difference\n",
    "        will be huge. If the leaves of the trees rustle in the background, then\n",
    "        the difference will be picked up too.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(type(bg_frame))\n",
    "    print(type(cur_frame))\n",
    "    \n",
    "    diff = cv2.absdiff(bg_frame, cur_frame)\n",
    "    \n",
    "    threshold_value = 10\n",
    "    set_to_value = 255\n",
    "    _, diff = cv2.threshold(diff, threshold_value, set_to_value, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # use median filtering to fill some holes of the moving foreground\n",
    "    diff = cv2.medianBlur(diff,5)\n",
    "    \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vid_frame(frame):\n",
    "    \"\"\"\n",
    "        Do some preprocessing work on a frame of a video to \n",
    "        make it ready for image processing techniques.\n",
    "        1) Convert frame to grayscale\n",
    "        2) Apply gaussian blur to get rid of noise\n",
    "    \"\"\"\n",
    "    # convert frame to grayscale\n",
    "    new_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # gaussian blur with 5x5 kernel\n",
    "    new_frame = cv2.GaussianBlur(new_frame,(5,5), 0)\n",
    "    \n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(frames):\n",
    "    \"\"\"\n",
    "        Use bitwise OR to stack frames together\n",
    "    \"\"\"\n",
    "    res = cv2.bitwise_or(frames[0], frames[1])\n",
    "    \n",
    "    for i in range(2, len(frames)):\n",
    "        res = cv2.bitwise_or(res, frames[i])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_parabola(frame):\n",
    "    \"\"\"\n",
    "        Determine if a shot parabola exists in frame\n",
    "    \"\"\"\n",
    "    \n",
    "    frame = cv2.Canny(frame,threshold1 = 70, threshold2 = 120)\n",
    "#     cv2.imshow('canny parabola', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_bball(frame, output):\n",
    "    \"\"\"\n",
    "        Use Hough Circle method\n",
    "        to locate basketball in frame\n",
    "        \n",
    "        Reference: https://www.pyimagesearch.com/2014/07/21/\n",
    "                   detecting-circles-images-using-opencv-hough-circles/\n",
    "        \n",
    "        output frame is the frame you want to draw the\n",
    "        identifier circle on\n",
    "    \"\"\"\n",
    "    \n",
    "    # canny edge test\n",
    "    frame = cv2.Canny(frame,threshold1 = 70, threshold2 = 120)\n",
    "#     cv2.imshow('canny edge', frame)\n",
    "    \n",
    "    \n",
    "    circles = cv2.HoughCircles(frame, cv2.HOUGH_GRADIENT, dp = 2, minDist = 400,\n",
    "                               param1 = 5, param2 = 65,\n",
    "                               minRadius = 0, maxRadius = 60)\n",
    "    \n",
    "#     circles = cv2.HoughCircles(frame, cv2.HOUGH_GRADIENT, dp = 5, minDist = 20,\n",
    "#                                param1 = 50, param2 = 100,\n",
    "#                                minRadius = 0, maxRadius = 300)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        \n",
    "        for (x,y,r) in circles:\n",
    "            # draw the outer circle\n",
    "            cv2.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "            # draw the center of the circle\n",
    "            cv2.circle(output, (x, y), 2, (0, 255, 0), 3)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_components(frame, output):\n",
    "    \"\"\"\n",
    "        Get connected pixel blobs\n",
    "        Reference: https://stackoverflow.com/questions/35854197/\n",
    "                   how-to-use-opencvs-connected-components-with-stats-in-python\n",
    "                   \n",
    "        Input frame is a frame that has been thresholded\n",
    "        Output frame is frame to draw connected component results on\n",
    "    \"\"\"\n",
    "    \n",
    "    connectivity = 4\n",
    "    cc = cv2.connectedComponentsWithStats(frame, connectivity, cv2.CV_32S)\n",
    "    \n",
    "    # The first cell is the number of labels\n",
    "    num_labels = cc[0]\n",
    "    # The second cell is the label matrix\n",
    "    labels = cc[1]\n",
    "    # The third cell is the stat matrix\n",
    "    stats = cc[2]\n",
    "    # The fourth cell is the centroid matrix\n",
    "    centroids = cc[3]\n",
    "    \n",
    "    print(num_labels)\n",
    "    print(labels)\n",
    "    print(stats)\n",
    "    print(centroids)\n",
    "    for (x,y) in centroids:\n",
    "        # draw the center of the circle\n",
    "        x, y = int(x), int(y)\n",
    "        cv2.circle(output, (x, y), 2, (0, 255, 0), 3)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blobs(frame, output):\n",
    "    \"\"\"\n",
    "        Get all the blobs (connected components of white pixels)\n",
    "        in a thresholded black and white image\n",
    "        \n",
    "        Reference: https://www.pyimagesearch.com/2015/05/25/\n",
    "                   basic-motion-detection-and-tracking-with-python-and-opencv/\n",
    "                   \n",
    "        Blobs info is a list of dictionaries containing coordinates\n",
    "        and size of blobs\n",
    "    \"\"\"\n",
    "    \n",
    "    cnts = cv2.findContours(frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    \n",
    "    blobs_info = {}\n",
    "    \n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # if the contour is too small, ignore it\n",
    "        if cv2.contourArea(c) < 100:\n",
    "            continue\n",
    "            \n",
    "        # find the bounding box for the contour\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        blobs_info['x'], blobs_info['y'] = x, y\n",
    "        blobs_info['width'], blobs_info['height'] = w, h\n",
    "    \n",
    "    return output, blobs_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Video Processing - Find all blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_blobs(video):\n",
    "    # record the last 3 frames of video for foreground detection\n",
    "    frames = deque()\n",
    "    frames.append(preprocess_vid_frame(video.read()[1]))\n",
    "    frames.append(preprocess_vid_frame(video.read()[1]))\n",
    "    frames.append(preprocess_vid_frame(video.read()[1]))\n",
    "\n",
    "    # record the last 50 frames of foreground detection for frame stacking\n",
    "    frames_foreground = deque()\n",
    "\n",
    "\n",
    "    # record blobs information\n",
    "    blobs_info = []\n",
    "\n",
    "    frame_count = 0\n",
    "    while(video.isOpened()):\n",
    "        frame_count += 1\n",
    "\n",
    "        # current frame of consideration is the middle frame in frames deque\n",
    "        cur_frame = frames[1]\n",
    "\n",
    "\n",
    "        # find moving foreground\n",
    "        foreground = get_moving_foreground(frames[0], frames[1], frames[2])\n",
    "        cv2.imshow('Foreground', foreground)\n",
    "\n",
    "\n",
    "        # find blobs and record blobs information\n",
    "        blobs_frame = cv2.cvtColor(cur_frame, cv2.COLOR_GRAY2RGB)\n",
    "        blobs_frame, b_info = get_blobs(foreground, blobs_frame)\n",
    "        b_info['frame_idx'] = frame_count\n",
    "        blobs_info.append(b_info)\n",
    "        cv2.imshow('Detected Blobs',blobs_frame)\n",
    "\n",
    "\n",
    "        # stack last 10 foreground frames together\n",
    "    #     frames_foreground.append(foreground)\n",
    "    #     if (len(frames_foreground) > 50):\n",
    "    #         frames_foreground.popleft()\n",
    "    #         stacked_foregrounds = stack_frames(frames_foreground)\n",
    "    #         cv2.imshow('Foregrounds stacked', stacked_foregrounds)\n",
    "    #         shot_parabola(stacked_foregrounds)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # get next frame\n",
    "        frames.popleft()\n",
    "        ret, next_frame = video.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frames.append(preprocess_vid_frame(next_frame))\n",
    "    \n",
    "    width  = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    blobs_df = pd.DataFrame(blobs_info)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return blobs_df, (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"../data/shooting_vids/shooting6.mp4\")\n",
    "\n",
    "blobs_df, frame_dim = find_blobs(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blobs_df.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Find Bball Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bball_blobs(blobs_info_df, frame_size):\n",
    "    \"\"\"\n",
    "        Find all the blobs that are the basketball and label them\n",
    "    \"\"\"\n",
    "    \n",
    "    blobs_df = blobs_info_df.copy(deep = True)\n",
    "    \n",
    "    # convert y axis so that it goes from bottom to top\n",
    "    blobs_df['y'] = frame_size[1] - blobs_df['y']\n",
    "    \n",
    "    # create column in pandas dataframe for labeling blob as bball\n",
    "    blobs_df['is_bball'] = False\n",
    "    \n",
    "    # hyperparameters to determine what blobs count as a basketball\n",
    "    BLOB_DIST = 100\n",
    "    BLOB_SIZE_TOL = 0.3\n",
    "    \n",
    "    def get_dist(row, cur_x, cur_y):\n",
    "        return ((row['x'] - cur_x)**2 + (row['y'] - cur_y)**2)**(1/2)\n",
    "\n",
    "    def similar_shape(row, cur_w, cur_h):\n",
    "        new_w, new_h = row['width'], row['height']\n",
    "        tol_w, tol_h = cur_w * BLOB_SIZE_TOL, cur_h * BLOB_SIZE_TOL\n",
    "\n",
    "        tol_w_lower, tol_w_upper = cur_w - tol_w, cur_w + tol_w\n",
    "        tol_h_lower, tol_h_upper = cur_h - tol_h, cur_h + tol_h\n",
    "\n",
    "        return (new_w >= tol_w_lower and new_w <= tol_w_upper and\n",
    "                new_h >= tol_h_lower and new_h <= tol_h_upper)\n",
    "\n",
    "    def find_ball_blob(blob_idx, time_forward):\n",
    "        \"\"\"\n",
    "            Find the ball blob that is closest to the current ball blob\n",
    "            that is similar in size timewise. Return None is no ball \n",
    "            blob can be found\n",
    "        \"\"\"\n",
    "        cur_blob = blobs_df.loc[blob_idx]\n",
    "        cur_x, cur_y = cur_blob['x'], cur_blob['y']\n",
    "        cur_w, cur_h = cur_blob['width'], cur_blob['height']\n",
    "        \n",
    "        if math.isnan(cur_x):\n",
    "            return None\n",
    "        \n",
    "        # get all the blobs one timestep forward or one timestep backwards\n",
    "        cur_frame_idx = blobs_df.loc[blob_idx]['frame_idx']\n",
    "        frame_idx = (cur_frame_idx + 1) if time_forward else (cur_frame_idx - 1)\n",
    "        blobs = blobs_df[blobs_df['frame_idx'] == frame_idx].copy(deep = True)\n",
    "\n",
    "        # find the distance of all blobs to current blob\n",
    "        blobs['distance'] = blobs.apply(get_dist, cur_x = cur_x, cur_y = cur_y, axis = 1)\n",
    "\n",
    "        # determine of blobs are similar shape to current blob\n",
    "        blobs['similar_shape'] = blobs.apply(similar_shape, cur_w = cur_w, cur_h = cur_h, axis = 1)\n",
    "\n",
    "        valid_blobs = blobs[(blobs['distance'] < BLOB_DIST) & (blobs['similar_shape'])]\n",
    "\n",
    "        # only return blob index if there is one valid blob\n",
    "        # multiple blobs mean algorithm cannot discern basketball between multiple blobs\n",
    "#         print(valid_blobs)\n",
    "        if valid_blobs.shape[0] == 1:\n",
    "            print(\"RETURNED STH USEFUL\")\n",
    "            return valid_blobs.index[0]\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def get_idx_ranges(indices):\n",
    "        \"\"\"\n",
    "            Get the start and end value of continuous indices\n",
    "            [1,2,3,4,7,8,9,14,15,16] --> [(1,4), (7,9), (14,16)]\n",
    "            \n",
    "            Expects a sorted list of indices\n",
    "        \"\"\"\n",
    "        start, end = indices[0], 0\n",
    "        cur = start + 1\n",
    "        index_ranges = []\n",
    "        for i in indices[1:]:\n",
    "            if i != cur:\n",
    "                end = cur - 1\n",
    "                index_ranges.append((start, end))\n",
    "                start = i\n",
    "                cur = i + 1\n",
    "            else:\n",
    "                cur += 1\n",
    "            if i == a[-1]:\n",
    "                end = i\n",
    "                index_ranges.append((start, end))\n",
    "        return index_ranges\n",
    "    \n",
    "    \n",
    "    \n",
    "    # any blob above 95% of max blob height is considered bball\n",
    "    # the 95% is used to account for varying shot arcs (ball reaches different heights)\n",
    "    ball_max_height = blobs_df['y'].max()\n",
    "    ball_effective_height = ball_max_height * 0.80\n",
    "    blobs_df.loc[blobs_df['y'] >= ball_effective_height, 'is_bball'] = True\n",
    "    \n",
    "    \n",
    "    # get the indices of is_bball == True already\n",
    "    ball_idxs = blobs_df.index[blobs_df['is_bball']].tolist()\n",
    "    ball_idx_ranges = get_idx_ranges(ball_idxs)\n",
    "    \n",
    "    print(\"BALL INDEX RANGES\")\n",
    "    print(ball_idx_ranges)\n",
    "    print()\n",
    "    for i, (ball_start, ball_end) in enumerate(ball_idx_ranges):\n",
    "        \n",
    "#         if i == 2:\n",
    "#             break\n",
    "        \n",
    "        print((ball_start, ball_end))\n",
    "        # trace the balls until they can't be found backwards/forwards in time\n",
    "        ball_idx = ball_start\n",
    "        while(True):\n",
    "            # get previous ball index\n",
    "            ball_idx = find_ball_blob(ball_idx, time_forward = False)\n",
    "            # if no ball is found, stop looking\n",
    "            if ball_idx is None:\n",
    "                print(\"no ball found 1\")\n",
    "                break\n",
    "            # label ball\n",
    "            blobs_df.loc[ball_idx, \"is_bball\"] = True\n",
    "        \n",
    "            \n",
    "        # trace the balls until they can't be found forwards in time\n",
    "        ball_idx = ball_end\n",
    "        while(True):\n",
    "            # get previous ball index\n",
    "            ball_idx = find_ball_blob(ball_idx, time_forward = True)\n",
    "            # if no ball is found, stop looking\n",
    "            if ball_idx is None:\n",
    "                print('no ball found 2')\n",
    "                break\n",
    "            # label ball\n",
    "            blobs_df.loc[ball_idx, \"is_bball\"] = True\n",
    "        \n",
    "    \n",
    "    # convert y axis back so that it can be plotted by opencv\n",
    "    blobs_df['y'] = frame_dim[1] - blobs_df['y']\n",
    "    \n",
    "    return blobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALL INDEX RANGES\n",
      "[(183, 187), (424, 437), (700, 707), (709, 714), (716, 719), (919, 926), (928, 939), (1099, 1104), (1106, 1111), (1113, 1117), (1276, 1282), (1284, 1285), (1287, 1295), (1487, 1506), (1664, 1680), (1878, 1884), (1888, 1889), (1892, 1899), (2175, 2191), (2193, 2193), (2294, 2306), (2308, 2311), (2495, 2512), (2611, 2622), (2928, 2942), (3151, 3185)]\n",
      "\n",
      "(183, 187)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(424, 437)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(700, 707)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(709, 714)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(716, 719)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(919, 926)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(928, 939)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1099, 1104)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1106, 1111)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1113, 1117)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1276, 1282)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1284, 1285)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1287, 1295)\n",
      "no ball found 1\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 2\n",
      "(1487, 1506)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1664, 1680)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1878, 1884)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1888, 1889)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(1892, 1899)\n",
      "no ball found 1\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 2\n",
      "(2175, 2191)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(2193, 2193)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(2294, 2306)\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(2308, 2311)\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(2495, 2512)\n",
      "no ball found 1\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "RETURNED STH USEFUL\n",
      "no ball found 2\n",
      "(2611, 2622)\n",
      "RETURNED STH USEFUL\n",
      "no ball found 1\n",
      "no ball found 2\n",
      "(2928, 2942)\n",
      "no ball found 1\n",
      "RETURNED STH USEFUL\n",
      "no ball found 2\n",
      "(3151, 3185)\n",
      "no ball found 1\n",
      "no ball found 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>is_bball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_idx   x   y  width  height  is_bball\n",
       "0          1 NaN NaN    NaN     NaN     False\n",
       "1          2 NaN NaN    NaN     NaN     False\n",
       "2          3 NaN NaN    NaN     NaN     False\n",
       "3          4 NaN NaN    NaN     NaN     False\n",
       "4          5 NaN NaN    NaN     NaN     False"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = find_bball_blobs(blobs_df, frame_dim)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to plot basketball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bball(video, ball_df):\n",
    "    \n",
    "    # record the last 3 frames of video for foreground detection\n",
    "    frames = deque()\n",
    "    frames.append(preprocess_vid_frame(video.read()[1]))\n",
    "    frames.append(preprocess_vid_frame(video.read()[1]))\n",
    "    frames.append(preprocess_vid_frame(video.read()[1]))\n",
    "\n",
    "\n",
    "    frame_count = 0\n",
    "    while(video.isOpened()):\n",
    "        frame_count += 1\n",
    "\n",
    "        # current frame of consideration is the middle frame in frames deque\n",
    "        cur_frame = frames[1]\n",
    "        \n",
    "\n",
    "        # find moving foreground\n",
    "        foreground = get_moving_foreground(frames[0], frames[1], frames[2])\n",
    "        cv2.imshow('Foreground', foreground)\n",
    "\n",
    "\n",
    "        # label basketball in each frame\n",
    "        bballs_labeled = cv2.cvtColor(cur_frame.copy(), cv2.COLOR_GRAY2BGR)\n",
    "        blobs = ball_df[(ball_df['frame_idx'] == frame_count) &\n",
    "                        (ball_df['is_bball'])]\n",
    "        for _, blob in blobs.iterrows():\n",
    "            x, y, w, h = int(blob['x']), int(blob['y']), int(blob['width']), int(blob['height'])\n",
    "            cv2.rectangle(bballs_labeled, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(bballs_labeled, \"Basketball!\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.imshow('Bballs Labeled', bballs_labeled)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # get next frame\n",
    "        frames.popleft()\n",
    "        ret, next_frame = video.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frames.append(preprocess_vid_frame(next_frame))\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"../data/shooting_vids/shooting6.mp4\")\n",
    "\n",
    "plot_bball(video, res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-73bc2d64bc09>\u001b[0m in \u001b[0;36monChange\u001b[0;34m(trackbarValue)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackbarValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mywindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-73bc2d64bc09>\u001b[0m in \u001b[0;36monChange\u001b[0;34m(trackbarValue)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackbarValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mywindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-73bc2d64bc09>\u001b[0m in \u001b[0;36monChange\u001b[0;34m(trackbarValue)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackbarValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mywindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-73bc2d64bc09>\u001b[0m in \u001b[0;36monChange\u001b[0;34m(trackbarValue)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackbarValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mywindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-73bc2d64bc09>\u001b[0m in \u001b[0;36monChange\u001b[0;34m(trackbarValue)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackbarValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mywindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-73bc2d64bc09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mywindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(\"../data/shooting_vids/shooting6.mp4\")\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "def onChange(trackbarValue):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,trackbarValue)\n",
    "    err,img = cap.read()\n",
    "    cv2.imshow(\"mywindow\", img)\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('mywindow')\n",
    "cv2.createTrackbar( 'start', 'mywindow', 0, length, onChange )\n",
    "cv2.createTrackbar( 'end'  , 'mywindow', 100, length, onChange )\n",
    "\n",
    "onChange(0)\n",
    "cv2.waitKey()\n",
    "\n",
    "start = cv2.getTrackbarPos('start','mywindow')\n",
    "end   = cv2.getTrackbarPos('end','mywindow')\n",
    "if start >= end:\n",
    "    raise Exception(\"start must be less than end\")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,start)\n",
    "while cap.isOpened():\n",
    "    err,img = cap.read()\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) >= end:\n",
    "        break\n",
    "    cv2.imshow(\"mywindow\", img)\n",
    "    k = cv2.waitKey(10) & 0xff\n",
    "    if k==27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
